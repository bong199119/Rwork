a[(length(a)-5) : length(a)]
a[a>=10&a<=50]
a[a>=10 & a<=50]
a[-5:100]
length(a)
a[(length(a)-5) : length(a)]
a[length(a)-5:length(a)]
a[100-5:100]
# matrix()
m1 <- matrix(c(1:9), nrow =3)
m1
dim(m1) # 3 3
x1 <- 1:5 #c(1:5)
x1
x2 <- 2:6
x1; x2
# rbind()
rbind(x1, x2)
# rbind()
m2 <-rbind(x1, x2)
m2
dim(m2)
m3 <- cbind(x1,x2)
m3
#matrix index
m3[row, col]
#matrix index
m3[1, 2]
m3[1,]
m3[,2]
#box
m2 [c(1:2),c(2:4)]
m2 [(1,2),(2,3,4)]
x <- matrix(1:9, nrow = 3, ncol = 3,byrow = TRUE)
x
colnames(x) <- c("one","two","three")
x
# broadcast 연산
x <- 1:10
x*0.5
y <- matrix(1:6, nrow = 2)
# 2) vector vs matrix
x <- 1:3
y <- matrix(1:6, nrow = 2)
dim(y)
y
z<- x*y
z
# 2) vector vs matrix
x <- 1:3
x
y <- matrix(1:6, nrow = 2)
y
z<- x*y
z
# apply() : 처리  행간 혹은 열간 합
apply(z, 1, sum)
apply(z, 2, mean)
apply(z,2,sum)
apply(z, 2, max)
arr <- array(1:12, c(3,2,2))
arr
dim(arr)
# apply() : 처리  행간 혹은 열간 합
apply(z, 1, sum)
arr <- array(1:12, c(3,2,2))
arr
dim(arr) #
data.frame(NO=no, Name=name, Age=age, Pay=pay)
no <- 1:3
name <- c("홍길동","이순신","유관순")
age <- c(35,45,25)
pay <- c(200,300,150)
data.frame(NO=no, Name=name, Age=age, Pay=pay)
#obj$column
epay <- emp$Pay
emp <- data.frame(NO=no, Name=name, Age=age, Pay=pay)
emp
#obj$column
epay <- emp$Pay
epay
var(epay)
sd(epay)
sqrt(var(epay))
sd(epay)
#2) Vec2 벡터 변수에 1~10까지 3간격으로 연속된 정수를 만드시오.
seq(1:10 by=3)
#1) Vec1 벡터 변수를 만들고, 1~5까지 연속된 정수를 만드시오.
c(1:5)
seq(1,10 by=3)
seq(1,10, by=3)
seq(1:10, by=3)
seq(1,10, by=3)
seq
seq(25,-15, by = 5)
seq(25,-15, by=5)
seq(25,(-15), by=5)
seq(25,-15, by=5)
seq
seq(1,10, 3)
seq
seq
seq(1,10, 3)
seq
seq
seq(1,10, 3)
seq
vec2 <- seq(1,10, 3)
vec2
vec1 <- c(1:5)
vec3 <- c(vec1, vec2)
vec4 <- c(vec1, vec2)
vec4
#3) Vec3 벡터 변수에 "R" 문자가 5회 반복되도록 하시오.
vec3 <- rep("r", 5)
vec3
seq(25,-15, by=5)
m <- rbind(v1,v2)
m
# 02. 다음 두 개의 벡터를 이용하여 단계별로 처리하시오.
v1 <- c(2,3,10,-5,8)
v2 <- c(40,50,-30,7,10)
m <- rbind(v1,v2)
m
dim(m)
m<- cbind(v1,v2)
m
seq(25,-15, -5)
vec5 <- vec4[seq(1,length(vec4),2)]
vec5
apply(m,2,sum)
# <조건1> 위 7개 벡터를 user이름으로 데이터 프레임 생성
user <- data.frame(name, age, gender,job,sat,grade,total)
name <-c("최민수","유관순", "이순신","김유신","홍길동")
age <-c(55,45,45,53,15) #연령
gender <-c(1,2,1,1,1) #1:남자, 2: 여자
job <-c("연예인","주부","군인","직장인","학생")
sat <-c(3,4,2,5,5) # 만족도
grade <- c("C","C","A","D","A")
total <-c(44.4,28.5,43.5,NA,27.1) #총구매금액(NA:결측치)
# <조건1> 위 7개 벡터를 user이름으로 데이터 프레임 생성
user <- data.frame(name, age, gender,job,sat,grade,total)
user
# <조건2> 총구매금액(total) 변수를 이용하여 히스토그램 그리기-hist()
hist(user$total)
# <조건3> 만족도(sat) 변수를 이용하여 산점도 그리기-plot()
plot(user$sat)
kor <- c(90,85,90)
eng <- c(70,85,75)
mat <- c(86,92,88)
# 조건1) 3개의 과목점수를 이용하여 데이터프레임(Data)을 생성한다.
data<- data.frame(kor,eng,mat)
data
# 조건2) 행/열 방향으로 max()함수를 적용하여 최댓값 구하기
apply(data,1,max)
apply(data,2,max)
# 조건3) 행/열 방향으로 mean()함수를 적용하여 평균 구하기(소숫점 2자리 까지 표현)
#  힌트 : round(data, 자릿수)
round(apply(data,1,mean),2)
round(apply(data,2,mean),2)
score <- c(90,85,83)
# 분산
var(score)
# 분산
var(score) # 13
# 표준편차 : 분산의 양의 제곱근
sd(score)
# 표준편차 : 분산의 양의 제곱근
sd(score) # 3.605551
sqrt(var(score))
sqrt(var(score)) # 3.605551
#분산 = sum((x-산술평균)^2) / n-1
avg <- mean(score) # 산술평균
diff <- (score - avg)
diff <- (score - avg)^2
diff
diff <- (score - avg)^2
diff_sum <- sum(diff)
var <- diff_sum / (length(score) - 1)
var
sd <- sqrt(var)
sd
# 1) key 생략 : [key =] value
list <- list('lee',"이순신",29,"hong","홍길동",45)
# key -> value 접근
list[[1]] -> "lee"의 키값
# key -> value 접근
list[[1]]  #-> "lee"의 key
list[[2]]  #-> "이순신"의 key
# index -> key:value 접근
list[4] # -> [[4]],  "hong"
install.packages("stringr")
library(stringr)
str <- "홍길동35이순신45"
str_extract_all(str, "[가-힣]{3}")
member = list(name = c("홍길순", "이순신"),
age = c(33,44),
gender = ㅊ("여","남"))
member
member = list(name = c("홍길순", "이순신"),
age = c(33,44),
gender = c("여","남"))
member
member$name[2]
# 조건4) 행 단위 분산과 표준편차 구하기
#  힌트 : var(), sd()
apply(Data, 1, var)
apply(Data, 1, sd)
# 1. 모집단에서 표본 추출(1,000 학생)
x <- rnorm(1000, mean = 165.2, sd = 1) # 정규분포
hist(x)
# 정규성 결정
# 귀무가설 : 정규분포와 차이가 없다.
shapiro.test(x)
# 2. 평균차이 검정 : 평균 : 165.2cm
t.test(x, mu=165.2)
# t = -0.55503, df = 999, p-value = 0.579
# t, df : 검정통계량
# p-value : 유의확률
# p-value = 0.579 >= 0.05 -> 귀무가설 채택
# 95 percent confidence interval: 95%
# 165.1071 ~ 165.2309 : 신뢰구간(채택역)
# mean of x
# 165.1832 -> 실제 평균
mean(x)
# t = -0.55503, df = 999, p-value = 0.579
# t, df : 검정통계량
# p-value : 유의확률
# p-value = 0.579 >= 0.05 -> 귀무가설 채택
# 95 percent confidence interval: 95%
# 165.1071 ~ 165.2309 : 신뢰구간(채택역)
# mean of x
# 165.169 -> 실제 평균
mean(x) # 165.169
# 3. 기각역의 평균검정
t.test(x, mu=165.09, conf.level = 0.95) # 95%
# 4. 신뢰수준 변경(95% -> 99%)
t.test(x, mu=165.2, conf.level = 0.99)
# 정규붙포
n <- 2000
rnorm(n, mean = 100, sd = 10)
x <- rnorm(n, mean = 100, sd = 10)
x
shapiro.test(x)
# 표준화
# 표준화 공식(z) = (x - mu) / sd(x)
mu <- mean(x)
# 표준화
# 표준화 공식(z) = (x - mu) / sd(x)
mu <- mean(x)
mu
z = (x - mu) / sd(x)
z
hist(z)
mean(z)
sd(z) # 1
?sd
# scale() 함수 이용
z2 <- as.data.frame(scale(x)) # matrix -> data.frame
z2
str(z2)
z2 <- z2$V1
hist(z2)
z2
mean(z2) # # 6.1
sd(z2)
# 2. 정규화
# - 특정 변수값을 일정한 범위(0 ~ 1)로 일치시키는 과정
str(iris)
head(iris)
summary(iris[-5])
# 정규화 -> data.frame 형변환
as.data.frame(scale(iris[-5]))
# 정규화 -> data.frame 형변환
iris_nor <- as.data.frame(scale(iris[-5]))
summary(iris_nor)
summary(iris[-5])
summary(iris_nor)
# 2) 정규화 함수 정의(0~1)
nor <- function(x){
n <- (x - min(x)) / (max(x) - min(x))
return (n)
}
iris_nor2 <- apply(iris[-5], 2, nor)
summary(iris_nor2)
head(iris_nor2)
df <- data.frame(no, score)
no <- 1:100 # 번호
score <- runif(100, min = 40, max = 100) # 성적
df <- data.frame(no, score)
df
nrow(df)
# 15명 학생 샘플링
sample(x = nrow(df), size = 15)
# 15명 학생 샘플링
idx <- sample(x = nrow(df), size = 15)
idx
sam <- df[idx, ]
sam
# train(70%)/test(30%) dataset
idx <- sample(x = nrow(df), size = nrow(df)*0.7)
idx
train <- df[idx, ]
test <- df[-idx, ]
dim(train)
dim(test)
# 05. iris 데이터셋을 대상으로 8:2비율로 sampling하여 train과 test 셋을 만드시오.
dim(iris)
nrow(iris)
idx <- sample(x = nrow(iris), size = nrow(iris)*0.8)
idx
dim(iris)
dim(idx)
train <- df[idx, ]
dim(train)
test <- df[-idx, ]
dim(test)
train <- iris[idx, ]
test <- iris[-idx, ]
dim(train)
dim(test)
# 50% vs 50%
idx <- sample(nrow(iris), nrow(iris)*0.5)
train <- iris[idx, ]
test <- iris[-idx, ]
dim(train)
dim(test)
head(iris)
# Sepal.Length : y(종속변수)
# Petal.Length : x(독립변수)
# model : 꽃잎 길이 -> 꽃받침 길이
model <- lm(Sepal.Length ~ Petal.Length, data = train )
pred <- model$fitted.values # 예측치(꽃받침 길이)
pred
# test ataset model
model2 <- lm(Sepal.Length ~ Petal.Length, data= test)
pred2 <- model2$fitted.values
# train_y
train_x <- train$Sepal.Length # train 정답
# test_y
test_x <- test$Sepal.Length # test 정답
# 정답 vs 예측치
plot(train_x, pred, col="blue", pch=18) # plot(x,y)
points(test_x, pred2, col="red",pch-19)
# 정답 vs 예측치
plot(train_x, pred, col="blue", pch=18) # plot(x,y)
points(test_x, pred2, col="red",pch-19)
points(test_x, pred2, col="red",pch=19)
col = c("blue", "red"), pch = c(18,19)
# 범례
legend("topleft", legend = c("train", "test"),
col = c("blue", "red"), pch = c(18,19))
plot(train_x,pred2)
plot(train_x,pred)
# train_y
train_x <- train$Petal.Length # train 정답
# 정답 vs 예측치
plot(train_x, pred, col="blue", pch=18) # plot(x,y)
# test_y
test_x <- test$Petal.Length # test 정답
points(test_x, pred2, col="red",pch=19) #
plot(train_x,pred)
# 정답 vs 예측치
plot(train_x, pred, col="blue", pch=18) # plot(x,y)
points(test_x, pred2, col="red",pch=19) #
pred
# train_y
train_x <- train$Sepal.Length # train 정답
# test_y
test_x <- test$Sepal.Length # test 정답
plot(train_x, test_x, col="blue", pch=18) # plot(x,y)
points(pred, pred2, col="red",pch=19) #
# train_y
train_x <- train$Petal.Length # train 정답
# 정답 vs 예측치
plot(train_x, pred, col="blue", pch=18) # plot(x,y)
test_y <- test$Petal.Length
points(test_x, test_y, col="red",pch=19) #
# test_y
test_x <- test$Petal.Length # test 정답
test_y <- test$Sepal.Length
plot(train_x, pred, col="blue", pch=18) # plot(x,y)
points(test_x, test_y, col="red",pch=19) #
pred
model
# 1. 변수 선택
str(iris)
# 3. 동질성 검정
bartlett.test(y ~ x)
# 1. 변수 선택
str(iris)
x <- iris$Species # 집단변수
y <- iris$Sepal.Width # 연속형
# 3. 동질성 검정
bartlett.test(y ~ x)
bartlett.test(Sepal.Width ~ Species, data=iris)
# 4. 분산분석 : aov(y ~ x, data)
model <- aov(Sepal.Width ~ Species, data = iris)
model
# 5. 분산분석 해석
summary(model)
# 6. 사후검정 : 각 집단 차이 상세히 분석
TukeyHSD(model)
plot(TukeyHSD(model))
# 통계검정 : 각 집단의 평균차이
library(dplyr)
iris %>% group_by(Species) %>% summarise(avg = mean(Sepal.Width))
2.77-3.43
# virginica-versicolor
2.97-2.77 #
names(iris)
x <- iris$Species
y <- iris$Sepal.Length
# 2. 동질성 검정
bartlett.test(Sepal.length ~ Species, data=iris)
y <- iris$Sepal.Length
# 2. 동질성 검정
bartlett.test(Sepal.length ~ Species, data=iris)
# 2. 동질성 검정
bartlett.test(Sepal.Length ~ Species, data=iris)
# 3. 분산분석(비모수 검정) : 평균 -> 중위수  평균에 편향을 가지고 있기 때문에!
kruskal.test(Sepal.Length ~ Species , data = iris)
# 4. 사후검정 : 집단별 중위수 비교
library(dplyr)
iris %>% group_by(Species) %>% summarise(med = median(Sepal.Length))
airquality
str(airquality)
# $ OZone -> y : 연속형 변수
# $ Month -> x : 집단변수
# 단계 1: 전처리(결측치 제거)
airquality$Ozone
# $ OZone -> y : 연속형 변수
# $ Month -> x : 집단변수
# 단계 1: 전처리(결측치 제거)
a <- omit(airquality$Ozone)
summary(iris_nor)
# $ OZone -> y : 연속형 변수
# $ Month -> x : 집단변수
# 단계 1: 전처리(결측치 제거)
a <- na.omit(airquality)
# 단계 2: 동질성 검정
bartlett.test(airquality$Ozone, airquality$Month)
# 단계 2: 동질성 검정
bartlett.test(airquality$Ozone ~ airquality$Month)
# 단계 3: 분산분석(모수 vs 비모수)
kruskal.test(Ozone ~ Month, data = airquality)
# 단계 4: 사후검정 : 집단별 중위수
dataset %>% group_by(Month) %>% summarise(med = median(Ozone))
# $ OZone -> y : 연속형 변수
# $ Month -> x : 집단변수
# 단계 1: 전처리(결측치 제거)
dataset <- na.omit(airquality)
# 단계 4: 사후검정 : 집단별 중위수
dataset %>% group_by(Month) %>% summarise(med = median(Ozone))
# 1. 전처리
str(quakes)
y <- quakes$mag # 연속형
x <- quakes$depth  # 집단변수(연속형 -> 범주형)
range(quakes$depth) #
680 - 40
div <- round(640 / 3)
div
# 코딩변경(연속형 -> 범주형)
quakes$depth2[quakes$depth <= (40 + div)] <- "low"
# 코딩변경(연속형 -> 범주형)
quakes$depth2[quakes$depth <= (40 + div)] <- "low"
quakes$depth2[quakes$depth > (40 + div) & quakes$depth <= (680-div)] <- "mid"
quakes$depth2[quakes$depth > (680 - div)] <- "high"
x <- quakes$mag
y <- quakes$depth2
table(quakes$depth2)
# 2. 동질성 검정
bartlett.test(mag ~ depth2, data = quakes)
# 3. 분산분석(모수 검정)
model <- aov(mag ~ depth2, data = quakes)
model
summary(model)
# 4. 사후 검정
TukeyHSD(model)
plot(TukeyHSD(model))
# dataset 가져오기
product <- read.csv("product.csv")
# dataset 가져오기
product <- read.csv("product.csv")
# dataset 가져오기
getwd()
setwd("C:/Rwork/data")
product <- read.csv("product.csv")
# 친밀도, 적절성, 만족도 : 5점(등간척도)
str(product)
cor(product, method = "pearson") # 상관계수 행렬
cor(x= product$제품_적절성, y = product$제품_만족도)
cor(product, method = "pearson") # 상관계수 행렬
cor(x= product$제품_적절성, y = product$제품_만족도)
# 2. 상관분석 시각화
install.packages("corrplot")
library(corrplot)
corr <- cor(product, method = "pearson") # 상관계수 행렬
corrplot(corr, method = "number")
corrplot(corr, method = "square")
corrplot(corr, method = "circle")
corrplot(corr, method = "color")
corrplot(corr, method = "pentagon")
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
chart.Correlation(product)
cov(product) # 공분산 행렬
cor(iris[-5])
# 양의 상관계수(0.9628654)
plot(iris$Petal.Length, iris$Petal.Width)
# 음의 상관계수(-0.4284401)
plot(iris$Petal.Length, iris$Sepal.Width)
